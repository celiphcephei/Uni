{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install azure-eventhub\n",
    "#pip install mysql-connector-python\n",
    "\n",
    "import time\n",
    "import os\n",
    "import asyncio\n",
    "import uuid\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import mysql.connector as MySQL\n",
    "\n",
    "from datetime import timedelta\n",
    "from azure.eventhub import EventHubProducerClient, EventData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_simulation():\n",
    "    # This script simulates the production of events for 10 devices.\n",
    "    devices = []\n",
    "    for x in range(0, 10):\n",
    "        devices.append(str(uuid.uuid4()))\n",
    "\n",
    "    # Create a producer client to produce and publish events to the event hub.\n",
    "    producer = EventHubProducerClient.from_connection_string(conn_str=\"Endpoint=sb://teccemiot.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=BibBUUm7q+lrTBHiJceia022cY1sqXAH++AEhDVj0T8=\", eventhub_name=\"teccemiot2\")\n",
    "\n",
    "    for y in range(0,20):    # For each device, produce 20 events. \n",
    "        event_data_batch = producer.create_batch() # Create a batch. You will add events to the batch later. \n",
    "        for dev in devices:\n",
    "            # Create a dummy reading.\n",
    "            reading = {'id': dev, 'timestamp': str(datetime.datetime.utcnow()), 'uv': random.random(), 'temperature': random.randint(70, 100), 'humidity': random.randint(70, 100)}\n",
    "            s = json.dumps(reading) # Convert the reading into a JSON string.\n",
    "            event_data_batch.add(EventData(s)) # Add event data to the batch.\n",
    "        producer.send_batch(event_data_batch) # Send the batch of events to the event hub.\n",
    "\n",
    "    # Close the producer.    \n",
    "    producer.close()\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_simulation_sql():\n",
    "    # This script simulates the production of events for 10 devices.\n",
    "    i = 0\n",
    "    devices = []\n",
    "    for x in range(0, 10):\n",
    "        devices.append(str(uuid.uuid4()))\n",
    "\n",
    "    sqlConn = MySQL.connect(host='localhost', user='root', passwd='', db='prueba_iot')\n",
    "    cur = sqlConn.cursor()\n",
    "\n",
    "    for y in range(0,20):    # For each device, produce 20 events. \n",
    "        for dev in devices:\n",
    "            sql = (\"INSERT INTO datos (idsensor, fechalectura, uv, humedad, temperatura) VALUES (%s, %s, %s, %s, %s)\")\n",
    "            val = (dev, datetime.datetime.utcnow() + timedelta(seconds=i), random.random(), random.randint(70, 100), random.randint(70, 100))\n",
    "            \n",
    "            try:\n",
    "                cur.execute(sql, val)\n",
    "                sqlConn.commit()\n",
    "                \n",
    "                print(cur.rowcount, \"record inserted.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            i=i+1\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_csv(filename):\n",
    "    # Create a producer client to produce and publish events to the event hub.\n",
    "    producer = EventHubProducerClient.from_connection_string(conn_str=\"Endpoint=sb://teccemiot.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=BibBUUm7q+lrTBHiJceia022cY1sqXAH++AEhDVj0T8=\", eventhub_name=\"teccemiot2\")\n",
    "    \n",
    "    event_data_batch = producer.create_batch() # Create a batch. You will add events to the batch later. \n",
    "\n",
    "    # read csvfile\n",
    "    with open(filename, 'r', encoding = 'utf8', newline='') as txtfile: \n",
    "        # creating a txt reader object \n",
    "        reader = csv.reader(txtfile, delimiter=',') \n",
    "\n",
    "        for line in reader:\n",
    "            reading = {'id': line[0], 'timestamp': str(datetime.datetime.utcnow()), 'temperature': line[1], 'humidity': line[2], 'light': line[3], 'co2': line[4], 'humidityRatio': line[5]}\n",
    "            s = json.dumps(reading) # Convert the reading into a JSON string.\n",
    "            \n",
    "            try:\n",
    "                event_data_batch.add(EventData(s)) # Add event data to the batch.\n",
    "            except ValueError:\n",
    "                # EventDataBatch object reaches max_size.\n",
    "                # New EventDataBatch object can be created here to send more data.\n",
    "                # break\n",
    "                producer.send_batch(event_data_batch) # Send the batch of events to the event hub.    \n",
    "                event_data_batch = producer.create_batch() # Create a batch. You will add events to the batch later.\n",
    "                event_data_batch.add(EventData(s)) # Add event data to the batch.\n",
    "            \n",
    "                continue\n",
    "\n",
    "    \n",
    "    producer.close() # Close the producer.\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sql():\n",
    "    # Create a producer client to produce and publish events to the event hub.\n",
    "    producer = EventHubProducerClient.from_connection_string(conn_str=\"\", eventhub_name=\"\")\n",
    "    \n",
    "    event_data_batch = producer.create_batch() # Create a batch. You will add events to the batch later. \n",
    "\n",
    "    sqlConn = MySQL.connect(host='localhost', user='root', passwd='', db='iot')\n",
    "    cur = sqlConn.cursor()\n",
    "    cur.execute(\"SELECT id, fecha, hora, valor, lectura from clima\")\n",
    "    \n",
    "    for id, fecha, hora, valor, lectura in cur.fetchall:\n",
    "        reading = {'id': id, 'fecha': fecha, 'hora': hora, 'valor': valor, 'lectura': lectura}\n",
    "        s = json.dumps(reading) # Convert the reading into a JSON string.\n",
    "            \n",
    "        try:\n",
    "            event_data_batch.add(EventData(s)) # Add event data to the batch.\n",
    "        except ValueError:\n",
    "            producer.send_batch(event_data_batch) # Send the batch of events to the event hub.    \n",
    "            event_data_batch = producer.create_batch() # Create a batch. You will add events to the batch later.\n",
    "            event_data_batch.add(EventData(s)) # Add event data to the batch.\n",
    "            \n",
    "            continue\n",
    "\n",
    "    \n",
    "    producer.close() # Close the producer.\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_event_data_batch(producer):\n",
    "    # the events will be distributed to available partitions via round-robin.\n",
    "    event_data_batch = await producer.create_batch(max_size_in_bytes=1000)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            event_data_batch.add(EventData('Message inside EventBatchData'))\n",
    "        except ValueError:\n",
    "            # EventDataBatch object reaches max_size.\n",
    "            # New EventDataBatch object can be created here to send more data.\n",
    "            break\n",
    "\n",
    "    await producer.send_batch(event_data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run():\n",
    "    producer = EventHubProducerClient.from_connection_string(\n",
    "        conn_str='',\n",
    "        eventhub_name=''\n",
    "    )\n",
    "    async with producer:\n",
    "        await send_event_data_batch(producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n",
      "1 record inserted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_simulation_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection string is either blank or malformed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\renat\\Documents\\_Codigos\\Uni\\TercerSemestre\\IOT\\EventHub\\EventHub.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_sql()\n",
      "\u001b[1;32mc:\\Users\\renat\\Documents\\_Codigos\\Uni\\TercerSemestre\\IOT\\EventHub\\EventHub.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_sql\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Create a producer client to produce and publish events to the event hub.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     producer \u001b[39m=\u001b[39m EventHubProducerClient\u001b[39m.\u001b[39;49mfrom_connection_string(conn_str\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, eventhub_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     event_data_batch \u001b[39m=\u001b[39m producer\u001b[39m.\u001b[39mcreate_batch() \u001b[39m# Create a batch. You will add events to the batch later. \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renat/Documents/_Codigos/Uni/TercerSemestre/IOT/EventHub/EventHub.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     sqlConn \u001b[39m=\u001b[39m MySQL\u001b[39m.\u001b[39mconnect(host\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m'\u001b[39m, user\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m'\u001b[39m, passwd\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, db\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39miot\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\eventhub\\_producer_client.py:523\u001b[0m, in \u001b[0;36mEventHubProducerClient.from_connection_string\u001b[1;34m(cls, conn_str, eventhub_name, buffered_mode, on_error, on_success, max_buffer_length, max_wait_time, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_connection_string\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m    428\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEventHubProducerClient\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    429\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create an EventHubProducerClient from a connection string.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[39m    :param str conn_str: The connection string of an Event Hub.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39m            :caption: Create a new instance of the EventHubProducerClient from connection string.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     constructor_args \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_from_connection_string(\n\u001b[0;32m    524\u001b[0m         conn_str,\n\u001b[0;32m    525\u001b[0m         eventhub_name\u001b[39m=\u001b[39meventhub_name,\n\u001b[0;32m    526\u001b[0m         buffered_mode\u001b[39m=\u001b[39mbuffered_mode,\n\u001b[0;32m    527\u001b[0m         on_success\u001b[39m=\u001b[39mon_success,\n\u001b[0;32m    528\u001b[0m         on_error\u001b[39m=\u001b[39mon_error,\n\u001b[0;32m    529\u001b[0m         max_buffer_length\u001b[39m=\u001b[39mmax_buffer_length,\n\u001b[0;32m    530\u001b[0m         max_wait_time\u001b[39m=\u001b[39mmax_wait_time,\n\u001b[0;32m    531\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconstructor_args)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\eventhub\\_client_base.py:329\u001b[0m, in \u001b[0;36mClientBase._from_connection_string\u001b[1;34m(conn_str, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    327\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_connection_string\u001b[39m(conn_str, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    328\u001b[0m     \u001b[39m# type: (str, Any) -> Dict[str, Any]\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     host, policy, key, entity, token, token_expiry \u001b[39m=\u001b[39m _parse_conn_str(\n\u001b[0;32m    330\u001b[0m         conn_str, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    331\u001b[0m     )\n\u001b[0;32m    332\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mfully_qualified_namespace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m host\n\u001b[0;32m    333\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39meventhub_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m entity\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\eventhub\\_client_base.py:73\u001b[0m, in \u001b[0;36m_parse_conn_str\u001b[1;34m(conn_str, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m eventhub_name \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39meventhub_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# type: Optional[str]\u001b[39;00m\n\u001b[0;32m     72\u001b[0m check_case \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcheck_case\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)  \u001b[39m# type: bool\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m conn_settings \u001b[39m=\u001b[39m core_parse_connection_string(\n\u001b[0;32m     74\u001b[0m     conn_str, case_sensitive_keys\u001b[39m=\u001b[39;49mcheck_case\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m check_case:\n\u001b[0;32m     77\u001b[0m     shared_access_key \u001b[39m=\u001b[39m conn_settings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mSharedAccessKey\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\core\\utils\\_connection_string_parser.py:28\u001b[0m, in \u001b[0;36mparse_connection_string\u001b[1;34m(conn_str, case_sensitive_keys)\u001b[0m\n\u001b[0;32m     26\u001b[0m cs_args \u001b[39m=\u001b[39m [s\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m conn_str\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mrstrip(\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mlen\u001b[39m(tup) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(tup) \u001b[39mfor\u001b[39;00m tup \u001b[39min\u001b[39;00m cs_args):\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mConnection string is either blank or malformed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m args_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(cs_args)\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cs_args) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(args_dict):\n",
      "\u001b[1;31mValueError\u001b[0m: Connection string is either blank or malformed."
     ]
    }
   ],
   "source": [
    "data_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv('DatosPruebaMQTT.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f75ef1f2c73763b58a5cda1c2fc96498446c2db431849e767f5872682e39cdda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
